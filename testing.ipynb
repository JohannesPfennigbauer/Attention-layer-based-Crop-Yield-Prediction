{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.   1980.     32.5     0.27    0.  ]\n",
      " [   0.   1981.     36.      0.6     0.  ]\n",
      " [   0.   1982.     37.      2.1     0.38]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "BigX = np.load('data/soybean_data_compressed.npz') ## order: locID, year, yield, W(52*6), S(6*11), P(14)\n",
    "X=BigX['data']\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=2)\n",
    "print(X[0:3, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.   1980.     32.5     0.27    0.  ]\n",
      " [   0.   1981.     36.      0.6     0.  ]\n",
      " [   0.   1982.     37.      2.1     0.38]]\n",
      "[[0.27 0.   1.62 0.4  0.97]\n",
      " [0.6  0.   0.04 0.   0.86]\n",
      " [2.1  0.38 1.68 0.53 6.34]]\n"
     ]
    }
   ],
   "source": [
    "X_train = X[X[:,1]<=2017]\n",
    "print(X_train[0:3, 0:5])\n",
    "\n",
    "X_train = X_train[:,3:]\n",
    "print(X_train[0:3, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7732/176784504.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  X[:,3:] = (X[:,3:]-M)/S\n"
     ]
    }
   ],
   "source": [
    "M=np.mean(X_train, axis=0, keepdims=True)\n",
    "S=np.std(X_train, axis=0, keepdims=True)\n",
    "X[:,3:] = (X[:,3:]-M)/S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low yield observations 2\n",
      "[1988. 2003.]\n"
     ]
    }
   ],
   "source": [
    "# Remove low yield observations\n",
    "X=np.nan_to_num(X)\n",
    "index_low_yield=X[:,2]<5\n",
    "print('low yield observations',np.sum(index_low_yield))\n",
    "print(X[index_low_yield][:,1])\n",
    "X=X[np.logical_not(index_low_yield)]\n",
    "del BigX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std 10.55 and mean 53.94  of test \n",
      "train data 24871\n",
      "test data 472\n"
     ]
    }
   ],
   "source": [
    "Index=X[:,1]==2018\n",
    "\n",
    "print('Std %.2f and mean %.2f  of test ' %(np.std(X[Index][:,2]), np.mean(X[Index][:,2])))\n",
    "print(\"train data\",np.sum(np.logical_not(Index)))\n",
    "print(\"test data\",np.sum(Index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25343, 395)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1980': np.float64(28.896072507552866), '1981': np.float64(33.37415565345081), '1982': np.float64(32.86419019316493), '1983': np.float64(26.874306569343062), '1984': np.float64(27.47536231884058), '1985': np.float64(34.75277777777778), '1986': np.float64(35.56026200873362), '1987': np.float64(35.70191176470588), '1988': np.float64(26.670444763271156), '1989': np.float64(32.388294797687855), '1990': np.float64(34.28272327964861), '1991': np.float64(34.376106194690266), '1992': np.float64(37.20850439882698), '1993': np.float64(33.805044510385756), '1994': np.float64(41.85523952095809), '1995': np.float64(35.0006015037594), '1996': np.float64(38.595927601809954), '1997': np.float64(39.79051094890511), '1998': np.float64(39.97238372093023), '1999': np.float64(37.414410480349346), '2000': np.float64(36.899146514935985), '2001': np.float64(39.67424023154848), '2002': np.float64(37.19884393063584), '2003': np.float64(32.673932253313694), '2004': np.float64(42.45685131195336), '2005': np.float64(43.46499261447563), '2006': np.float64(42.910225563909776), '2007': np.float64(42.597586726998486), '2008': np.float64(41.4822934232715), '2009': np.float64(46.00735294117647), '2010': np.float64(44.804761904761904), '2011': np.float64(42.21807817589577), '2012': np.float64(38.11724137931035), '2013': np.float64(44.40678899082569), '2014': np.float64(48.28428571428571), '2015': np.float64(50.42088974854932), '2016': np.float64(54.88854545454546), '2017': np.float64(51.120178571428575), '2018': np.float64(53.94385593220339)}\n"
     ]
    }
   ],
   "source": [
    "years = np.arange(1980, 2019)\n",
    "avg_values = {str(year): np.mean(X[X[:, 1] == year][:, 2]) for year in years}\n",
    "print(avg_values) # --> AVERAGE YIELD FOR EACH YEAR (INCLUDING 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1980': np.float64(-1.4582864093819747), '1981': np.float64(-0.8110332591297735), '1982': np.float64(-0.8847426432425297), '1983': np.float64(-1.7505084003420137), '1984': np.float64(-1.6636330086477271), '1985': np.float64(-0.6117699842181856), '1986': np.float64(-0.49505783412246773), '1987': np.float64(-0.4745840626898213), '1988': np.float64(-1.7799741766344916), '1989': np.float64(-0.9535276085675289), '1990': np.float64(-0.6797107179633866), '1991': np.float64(-0.6662133388457581), '1992': np.float64(-0.2568241871334897), '1993': np.float64(-0.7487534485560939), '1994': np.float64(0.4148055812735497), '1995': np.float64(-0.5759500402549351), '1996': np.float64(-0.05628882197700863), '1997': np.float64(0.11637385744519654), '1998': np.float64(0.142661382889246), '1999': np.float64(-0.22706293537032865), '2000': np.float64(-0.30153815477994156), '2001': np.float64(0.09956832131751261), '2002': np.float64(-0.2582204918169693), '2003': np.float64(-0.9122421440148659), '2004': np.float64(0.5017613420899283), '2005': np.float64(0.6474760625847064), '2006': np.float64(0.5672911465311062), '2007': np.float64(0.5221029565200785), '2008': np.float64(0.3609007008286591), '2009': np.float64(1.0149437216076767), '2010': np.float64(0.8411236268429317), '2011': np.float64(0.4672495522294741), '2012': np.float64(-0.1254771678385653), '2013': np.float64(0.7836014206069394), '2014': np.float64(1.344047014756093), '2015': np.float64(1.6528674736360232), '2016': np.float64(2.2986134626530217), '2017': np.float64(1.7539412765999902), '2018': np.float64(1.7539412765999902)}\n"
     ]
    }
   ],
   "source": [
    "avg2 = list(avg_values.values())\n",
    "mm = np.mean(avg2)\n",
    "ss = np.std(avg2)\n",
    "\n",
    "avg = {str(year): (value - mm) / ss for year, value in avg_values.items()}\n",
    "avg['2018'] = avg['2017']\n",
    "print(avg) # --> NORMALIZED AVERAGE YIELD FOR EACH YEAR (2018 REPLACED BY 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25343, 396)\n"
     ]
    }
   ],
   "source": [
    "# add normalized average yield to the data based on year\n",
    "X = np.concatenate((X, np.array([avg[str(int(year))] for year in X[:, 1]]).reshape(-1, 1)), axis=1)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6528674736360225\n",
      "2.2986134626530217\n",
      "1.75394127659999\n",
      "1.75394127659999\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X[X[:, 1] == 2015][:, -1]))\n",
    "print(np.mean(X[X[:, 1] == 2016][:, -1]))\n",
    "print(np.mean(X[X[:, 1] == 2017][:, -1]))\n",
    "print(np.mean(X[X[:, 1] == 2018][:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "time_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros(shape=[batch_size, time_steps, 396])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1997 1998]\n",
      "[2001 2002]\n",
      "[2001 2002]\n",
      "[[[ 363.   1997.     37.   ...   -0.07   -0.06    0.12]\n",
      "  [  30.   1998.     46.   ...   -0.07   -0.06    0.14]]\n",
      "\n",
      " [[ 575.   2001.     38.   ...   -0.07   -0.06    0.1 ]\n",
      "  [ 653.   2002.     36.6  ...   -0.07   -0.06   -0.26]]\n",
      "\n",
      " [[ 736.   2001.     32.2  ...   -0.07   -0.06    0.1 ]\n",
      "  [1029.   2002.     38.3  ...   -0.07   -0.06   -0.26]]]\n",
      "(3, 2, 396)\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    r1 = np.random.randint(0, 35)\n",
    "    years = np.array([(r1 + i) for i in range(time_steps)]) + 1980\n",
    "    print(years)\n",
    "    \n",
    "    for j, y in enumerate(years):\n",
    "        r2 = np.random.randint(X[X[:, 1] == y].shape[0])\n",
    "        out[i, j, :] = X[X[:, 1] == y][r2, :]\n",
    "\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [10.  6.  4.  0.  0.]\n",
      " [ 3.  1.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "BigX = np.load('data/soybean_data_compressed.npz') ## order: locID, year, yield, W(52*6), S(6*11), P(14)\n",
    "X=BigX['data']\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=2)\n",
    "print(X[0:3, -5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, time_steps = 5):\n",
    "    print(\"--- Preprocessing ---\")\n",
    "    # 1. remove low yield observations\n",
    "    X = np.nan_to_num(X)\n",
    "    index_low_yield = X[:,2] < 5\n",
    "    print(\"Remove low yield observations: \", np.sum(index_low_yield))\n",
    "    print(\"of years: \", X[index_low_yield][:, 1])\n",
    "    X = X[np.logical_not(index_low_yield)]\n",
    "    \n",
    "    # 2. calculate average yield of each year and standardize it\n",
    "    years = np.arange(1980, 2017)  # Exclude the last two years (2017 and 2018) for standardization\n",
    "    _avg = {str(year): np.mean(X[X[:, 1] == year][:, 2]) for year in years}\n",
    "    avg_m = np.mean(list(_avg.values()))\n",
    "    avg_s = np.std(list(_avg.values()))\n",
    "    \n",
    "    years = np.arange(1980, 2019)\n",
    "    avg = {str(year): np.mean(X[X[:, 1] == year][:, 2]) for year in years}\n",
    "    avg = {str(year): (value - avg_m) / avg_s for year, value in avg.items()}\n",
    "    \n",
    "    # 3. standardize the data on the training data only\n",
    "    X_train = X[X[:,1] <= 2016][:, 2:]\n",
    "    print(\"Full train data available: \", X_train.shape)\n",
    "\n",
    "    M=np.mean(X_train, axis=0, keepdims=True)\n",
    "    S=np.std(X_train, axis=0, keepdims=True)\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    X[:,2:] = (X[:,2:] - M) / (S + epsilon)\n",
    "    \n",
    "    # 4. add time steps  \n",
    "    for i in range(time_steps):\n",
    "        avg_prev = np.array([avg[str(int(year - i))] if (year - i) > 1979 else np.nan for year in X[:, 1] ])\n",
    "        X = np.concatenate((X, avg_prev.reshape(-1, 1)), axis=1)\n",
    "    \n",
    "    return X, M[0, 0], S[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preprocessing ---\n",
      "Remove low yield observations:  2\n",
      "of years:  [1988. 2003.]\n",
      "Full train data available:  (24311, 393)\n",
      "(25343, 395)\n",
      "(25343, 400)\n"
     ]
    }
   ],
   "source": [
    "X, M, S = preprocess_data(X)\n",
    "\n",
    "n_batches = 3\n",
    "time_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25343, 400)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(X, batch_size = 1000):\n",
    "    X_train = X[X[:, 1] <= 2016]\n",
    "    sample = np.zeros(shape = [batch_size, X.shape[1]])\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        r = np.random.randint(len(X_train))   # random index\n",
    "        obs = X_train[r]\n",
    "        sample[i] = obs\n",
    "\n",
    "    return sample.reshape(-1, X.shape[1])      # shape (n_batches*time_steps, 396 + time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 400)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample(X, batch_size = 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6928976489992175\n",
      "[-1.81 -0.91 -0.62 -0.6  -0.16]\n",
      "0.5680691631734047\n",
      "[-0.91 -0.62 -0.6  -0.16 -0.69]\n",
      "-0.5056279382996418\n",
      "[-0.62 -0.6  -0.16 -0.69  0.57]\n",
      "0.05753691455496316\n",
      "[-0.6  -0.16 -0.69  0.57 -0.51]\n",
      "0.24465411520448935\n",
      "[-0.16 -0.69  0.57 -0.51  0.06]\n",
      "-0.15978634421108592\n",
      "[-0.4  -1.81 -0.91 -0.62 -0.6 ]\n",
      "-0.6928976489992175\n",
      "[-1.81 -0.91 -0.62 -0.6  -0.16]\n",
      "0.5680691631734047\n",
      "[-0.91 -0.62 -0.6  -0.16 -0.69]\n",
      "-0.5056279382996418\n",
      "[-0.62 -0.6  -0.16 -0.69  0.57]\n",
      "0.05753691455496316\n",
      "[-0.6  -0.16 -0.69  0.57 -0.51]\n",
      "0.7333201149479038\n",
      "[ 0.23 -0.16 -0.87  0.66  0.82]\n",
      "0.6843489785936109\n",
      "[-0.16 -0.87  0.66  0.82  0.73]\n",
      "0.5096516153631387\n",
      "[-0.87  0.66  0.82  0.73  0.68]\n",
      "1.2184480939192959\n",
      "[0.66 0.82 0.73 0.68 0.51]\n",
      "1.0300765844659818\n",
      "[0.82 0.73 0.68 0.51 1.22]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 655.  , 1993.  ,   29.7 , ...,   -0.62,   -0.6 ,   -0.16],\n",
       "       [ 383.  , 1994.  ,   35.  , ...,   -0.6 ,   -0.16,   -0.69],\n",
       "       [  30.  , 1995.  ,   41.5 , ...,   -0.16,   -0.69,    0.57],\n",
       "       ...,\n",
       "       [ 582.  , 2008.  ,   43.5 , ...,    0.82,    0.73,    0.68],\n",
       "       [ 103.  , 2009.  ,   51.5 , ...,    0.73,    0.68,    0.51],\n",
       "       [ 721.  , 2010.  ,   33.1 , ...,    0.68,    0.51,    1.22]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sample_test(X, time_steps):\n",
    "    sample = []\n",
    "    X_test = X[X[:, 1] == 2018]\n",
    "\n",
    "    for obs in X_test:\n",
    "        avg_yield_values = []\n",
    "        \n",
    "        for k in range(time_steps):\n",
    "            prev_y = 2018 - k - 1\n",
    "            prev_data = X[X[:, 1] == prev_y]\n",
    "            avg_yield_values.append(prev_data[0, -1])\n",
    "        \n",
    "        avg_yield_values = np.array(avg_yield_values[::-1])\n",
    "        obs_with_avg_yield = np.concatenate((obs, avg_yield_values))\n",
    "        sample.append(obs_with_avg_yield)\n",
    "\n",
    "    return np.array(sample).reshape(-1, X.shape[1] + time_steps)    # shape (n_batches*time_steps, 396 + time_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
